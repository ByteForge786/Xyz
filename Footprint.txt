Hereâ€™s the revised version with a **clearer emphasis on carbon footprint reduction**:  

---  

As AI adoption grows in investment banking, the demand for **high-performance models** has led to increased **computational power usage**, straining **GPUs, data centers, and energy resources**, ultimately contributing to a **larger carbon footprint**. The energy-intensive nature of AI workloads results in **higher emissions**, making sustainability a critical challenge.  

A key contribution to addressing this challenge was **developing an AI model quantization framework**, which **reduces LLM precision to 8-bit**. By converting full-precision models to **low-bit versions**, we significantly **lowered energy consumption, reduced GPU workload, and minimized carbon emissions**. This not only made AI models **faster and more cost-effective** but also **enhanced sustainability** by cutting down the **computational power required**, thereby directly **reducing the carbon footprint** of AI-driven financial operations.  

By embracing quantization, we have successfully **optimized AI infrastructure**, ensuring that investment banks **leverage AI responsibly** while actively reducing their **environmental impact**. This contributes to a **greener, more sustainable future in finance**, aligning with **SDG 13 (Climate Action)**.  

---  

This keeps the **concise storytelling** while explicitly mentioning **carbon footprint reduction**. Let me know if you want any refinements!
