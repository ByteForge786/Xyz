Optimizing AI models through **quantization** is a powerful way to contribute to the **Sustainable Development Goals (SDGs), particularly SDG 13 (Climate Action)**. By reducing model precision, such as converting a large language model to **8-bit**, computational requirements decrease significantly, leading to **lower energy consumption and reduced carbon emissions**. This optimization allows AI models to run efficiently on **low-power hardware**, minimizing reliance on energy-intensive data centers. Additionally, quantization extends the lifespan of AI infrastructure by reducing hardware strain, thereby promoting **sustainable computing**. As AI adoption grows, making models more efficient ensures that technological advancements align with environmental responsibility, helping to combat climate change while maintaining high-performance AI solutions.



AI is rapidly transforming the **investment banking sector**, enhancing decision-making, automating processes, and optimizing financial strategies. From **algorithmic trading** to **risk assessment** and **ESG analysis**, AI is driving efficiency and innovation. However, the growing reliance on **large AI models** also increases **computational demands and energy consumption**, contributing to a larger carbon footprint.  

To align with **SDG 13 (Climate Action)**, one effective solution is **AI model quantization**â€”reducing model precision, such as converting large language models to **8-bit**. This significantly lowers **GPU power usage, decreases energy consumption, and enhances sustainability** without sacrificing performance. By making AI more efficient, investment banks can continue leveraging cutting-edge technology while minimizing environmental impact, ensuring a **greener and more responsible approach to AI-driven finance**.
